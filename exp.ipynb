{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f065fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install fastcoref\n",
    "!pip install chromadb\n",
    "!pip install gradio\n",
    "!pip install spacy[transformers]\n",
    "!git clone https://github.com/Ahmed-Khaled-Saleh/npat.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c00bd1a",
   "metadata": {},
   "source": [
    "## Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c7eed859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('data/enhanced_economics_data_v1.json', 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "442e591b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['authors', 'date_modify', 'description', 'filename', 'image_url', 'language', 'localpath', 'title', 'title_page', 'title_rss', 'source_domain', 'url', 'paragraphs', 'ID', 'linked_entites', 'related_persons'])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5b060512",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings\n",
    "\n",
    "client = chromadb.PersistentClient(\n",
    "    path=\"db\",\n",
    "    settings=Settings(),\n",
    "    tenant=DEFAULT_TENANT,\n",
    "    database=DEFAULT_DATABASE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "182ee9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = []\n",
    "for article in data['data']:\n",
    "    article_data = []\n",
    "    for i, ent in enumerate(article['linked_entites']):\n",
    "        quotes = []\n",
    "        for j, p_ents in enumerate(ent):\n",
    "            q = {}\n",
    "            if p_ents:\n",
    "                # print(f\"Source: {p_ents['Speaker']}, cue: {p_ents['Cue']}, quote: {p_ents['Quote']}\")\n",
    "                quote_str = f\"{p_ents['Speaker']} {p_ents['Cue']} {p_ents['Quote']}\"\n",
    "                q['Source'] = p_ents['Speaker']\n",
    "                q['Cue'] = p_ents['Cue']\n",
    "                q['Quote'] = p_ents['Quote']\n",
    "                q['quote_str'] = quote_str\n",
    "                quotes.append(q)\n",
    "        if len(quotes) > 0:\n",
    "            article_data.append({\n",
    "                'paragraph_index': i,\n",
    "                'quotes': quotes\n",
    "            })\n",
    "    filtered_data.append({\n",
    "        'article_id': article['ID'],\n",
    "        'title': article['title'],\n",
    "        'url': article['url'],\n",
    "        'quotes_data': article_data\n",
    "    })\n",
    "# with open('data/filtered_enhanced_economics_data_v1.json', 'w') as f:\n",
    "#     json.dump({'data': filtered_data}, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55c5fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client.get_or_create_collection(\"economics_quotes\")\n",
    "for article in filtered_data:\n",
    "    try:\n",
    "        collection.add(\n",
    "            documents=[q['quote_str'] for para in article['quotes_data'] for q in para['quotes']],\n",
    "            metadatas=[{\"source\": article['url']}]*sum([len(para['quotes']) for para in article['quotes_data']]),\n",
    "            ids=[f\"{article['article_id']}_quote_{i}\" for i in range(sum([len(para['quotes']) for para in article['quotes_data']]))],\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"Error adding quotes for article {article['article_id']}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333fbd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "llm, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-Instruct\",\n",
    "    max_seq_length = 2048,   \n",
    "    load_in_4bit = True,     \n",
    "    load_in_8bit = False,    \n",
    "    full_finetuning = False, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f28e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth.chat_templates import get_chat_template\n",
    "def get_response(relevant_quotes, user_query):\n",
    "    \n",
    "    sys_prompt = \"\"\"You are a helpful assistant that extracts relevant quotations from a set of articles based on user queries:\n",
    "    Given a user query, search the database of quotations and return the most relevant ones.\n",
    "    Provide the quotations along with their sources in a clear format.\n",
    "    If no relevant quotations are found, respond with \"No relevant quotations found.\"\n",
    "    Use the following format:\n",
    "    Quotation: \"<quote here>\"\n",
    "    Source: <source here>\n",
    "\n",
    "    Here are the relevant quotations:\n",
    "    {relevant_quotes}\n",
    "    User Query: \"{user_query}\"\n",
    "    Provide the relevant quotations below:\n",
    "    \"\"\"\n",
    "    tokenizer = get_chat_template(\n",
    "        tokenizer,\n",
    "        chat_template = \"llama-3.1\",\n",
    "    )\n",
    "    FastLanguageModel.for_inference(llm) \n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": sys_prompt.format(relevant_quotes=relevant_quotes, user_query=user_query)},\n",
    "    ]\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize = True,\n",
    "        add_generation_prompt = True, \n",
    "        return_tensors = \"pt\",\n",
    "    ).to(\"cuda\")\n",
    "\n",
    "    outputs = llm.generate(input_ids = inputs, max_new_tokens = 64, use_cache = True,\n",
    "                            temperature = 1.5, min_p = 0.1)\n",
    "    ans = tokenizer.batch_decode(outputs)\n",
    "    return ans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761539e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import time\n",
    "\n",
    "def respond(message, history):\n",
    "\n",
    "    res = collection.query(\n",
    "    query_texts=[message],\n",
    "    n_results=2,\n",
    ")\n",
    "    bot_message = f\"You said: {message}\"\n",
    "    ans = get_response(\n",
    "        relevant_quotes = res,\n",
    "        user_query = message,\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return ans\n",
    "\n",
    "with gr.ChatInterface(\n",
    "    fn=respond, \n",
    "    title=\"Quotation Miner\",\n",
    "    textbox=gr.Textbox(placeholder=\"Ask me a question...\", container=False, scale=7)\n",
    ") as demo:\n",
    "\n",
    "    demo.examples = [\n",
    "        [\"What did president Macron think about the coalition forces?\"],\n",
    "    ]\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c057d3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd9926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

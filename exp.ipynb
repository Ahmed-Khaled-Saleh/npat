{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a26525b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/cleaned_economics_data.json', 'r') as f:\n",
    "    articles = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f293604a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1186"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(articles['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8f6458",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd94095",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b630727",
   "metadata": {},
   "source": [
    "## Data Crawling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9866c84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsplease import NewsPlease\n",
    "\n",
    "def crawl_data(url):\n",
    "    article = NewsPlease.from_url(url)\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "206a00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from newsplease import NewsPlease\n",
    "url = 'https://www.theguardian.com/environment/2025/nov/29/climate-crisis-depleting-europe-groundwater-reserves-analysis'\n",
    "article = NewsPlease.from_url(url)\n",
    "# print(article.title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15ff02dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Revealed: Europe’s water reserves drying up due to climate breakdown'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a705141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "874"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(article.maintext.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b44307ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"article.json\", \"w\") as file:\n",
    "    json.dump(article.get_serializable_dict(), file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d7bbf3",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79936895",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_article(article):\n",
    "    cleaned_article = {\n",
    "        'title': article.title,\n",
    "        'authors': article.authors,\n",
    "        'date_publish': article.date_publish,\n",
    "        'maintext': article.maintext,\n",
    "        'url': article.url\n",
    "    }\n",
    "    return cleaned_article\n",
    "\n",
    "# for i, item in enumerate(articles['data']):\n",
    "#     articles['data'][i] = clean_article(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9916d46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/cleaned_economics_data.json', 'r') as f:\n",
    "    articles = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d00549",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621c553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc6fd8f4",
   "metadata": {},
   "source": [
    "## Quotation Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77db82da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ahmed/.local/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.cofenet.model.mod_bert import ModelBert_Cofe\n",
    "import torch\n",
    "\n",
    "model_cofe = ModelBert_Cofe()\n",
    "model_name = \"./src/cofenet/checkpoint/model_6000.bin\"\n",
    "state_dict = torch.load(model_name, map_location=torch.device('cpu'))\n",
    "model_cofe.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1f38b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.cofenet.utils.utils import *\n",
    "from src.cofenet.utils.loader import SingleDataLoader\n",
    "from src.cofenet.utils.dataset import DatasetBert\n",
    "from torch.utils.data import SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ad956ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tgidss2tgstrss(tgidss, tags_file_path ,lengths=None):\n",
    "    tgstrss = []\n",
    "    map_tg2tgid = {tag: idx for idx, tag in enumerate(load_text_file_by_line(tags_file_path))}\n",
    "    map_tgid2tg = {idx: tag for tag, idx in map_tg2tgid.items()}\n",
    "    \n",
    "    if lengths is None:\n",
    "        for tgids in tgidss:\n",
    "            tgstrss.append([map_tgid2tg[tgid] for tgid in tgids])\n",
    "    else:\n",
    "        for tgids, length in zip(tgidss, lengths):\n",
    "            tgstrss.append([map_tgid2tg[tgid] for tgid in tgids[:length]])\n",
    "    return tgstrss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "def read_data(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        raise Exception('data file_path is not exist')\n",
    "\n",
    "    with open(file_path, 'r', encoding='utf-8') as file_object:  \n",
    "        data = json.load(file_object)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import uuid\n",
    "def doc_text_preprocessing(doc):\n",
    "    global split_pargraphs\n",
    "    \n",
    "    def clean_text(txt):\n",
    "        txt = re.sub(r'(\\“|\\”)', \"\\\"\", txt)\n",
    "        txt = re.sub(r'[^a-zA-Z0-9 \\.\\'\\\"\\,\\-\\(\\)\\’\\$\\#\\@]', \"\", txt)\n",
    "        txt = re.sub(r'(\\( )', \"(\", txt)\n",
    "        txt = re.sub(r'( \\))', \")\", txt)\n",
    "        txt = re.sub(r'( \\.)', \".\", txt)\n",
    "        txt = re.sub(r'( \\,)', \",\", txt)\n",
    "        txt = re.sub(r'(.)\\.(.)', r'\\1. \\2', txt)\n",
    "        txt = re.sub(r' +', \" \", txt)\n",
    "        txt = re.sub(r'([a-z])\\.([a-z])', r'\\1 \\2', txt)\n",
    "        return txt.strip()\n",
    "\n",
    "    # clean text\n",
    "    doc['maintext'] = clean_text(doc['maintext'])\n",
    "\n",
    "    # check if there is no paragraphs to start split maintext\n",
    "    if len(doc['paragraphs']) == 0:\n",
    "       doc['paragraphs'] = split_pargraphs(doc['maintext'])\n",
    "\n",
    "    doc['paragraphs']  = list(filter(lambda x: len(x) > 1, map(lambda txt: clean_text(txt), doc['paragraphs'])))\n",
    "\n",
    "    # identify doc with id\n",
    "    doc['ID'] = str(uuid.uuid3(uuid.NAMESPACE_URL, doc['url']))\n",
    "    return doc\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d4a787de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "def handel_error(fun, doc):\n",
    "    try:\n",
    "        return fun(doc)\n",
    "    except Exception as e:\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "\n",
    "\n",
    "data = read_data('./data/cleaned_economics_data.json')['data']\n",
    "docs = map(lambda doc: handel_error(doc_text_preprocessing, doc), data)\n",
    "docs = list(filter(lambda x: x != None, docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02252980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1186"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8c55c525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from src.cofenet.utils.utils import *\n",
    "from src.cofenet.utils.loader import SingleDataLoader\n",
    "from src.cofenet.utils.dataset import DatasetBert\n",
    "from torch.utils.data import SequentialSampler\n",
    "\n",
    "\n",
    "def extract_quotes(infer_str:list, model_cofe) -> list:\n",
    "\n",
    "    file_path = read_write_str(infer_str, \"./src/cofenet/infer_file.txt\")\n",
    "    dataset = DatasetBert(file_path)\n",
    "    tag_file_path = './src/cofenet/utils/tag.txt'\n",
    "\n",
    "    dataloder = SingleDataLoader(dataset=dataset,\n",
    "                                batch_size=32,\n",
    "                                sampler=SequentialSampler(dataset),\n",
    "                                collate_fn=dataset.collate)\n",
    "    preds = []\n",
    "    for batch_data in dataloder:\n",
    "        model_cofe.eval()\n",
    "        with torch.no_grad():\n",
    "            batch_preds = model_cofe.predict(batch_data)\n",
    "            \n",
    "            batch_pred_strs = tgidss2tgstrss(\n",
    "                batch_preds.data.cpu().numpy() if not isinstance(batch_preds, list) else batch_preds, tag_file_path,\n",
    "                batch_data['lengths'].cpu().numpy())\n",
    "\n",
    "            preds.extend(batch_pred_strs)\n",
    "\n",
    "    os.remove(\"./src/cofenet/infer_file.txt\")\n",
    "    return preds\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "13d8a3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quote_cue_source_extraction(doc):\n",
    "\n",
    "    def clean_text(txt):\n",
    "        txt = txt.lower()\n",
    "        # txt = re.sub(r'[^a-zA-Z0-9 \\.\\$\\#\\@]', \"\", txt)\n",
    "        # txt = re.sub(r' +', \" \", txt)\n",
    "        # txt = re.sub(r'(\\. |\\.$)', \" \", txt)\n",
    "        # txt = re.sub(r'([a-z])\\.([a-z])', r'\\1 \\2', txt)\n",
    "        return txt.strip()\n",
    "\n",
    "    paragraphs = doc['paragraphs']\n",
    "\n",
    "    # extract Cue, Source, and Quotes\n",
    "    predict_entities = extract_quotes(paragraphs, model_cofe)\n",
    "    return doc, predict_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "101196f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13/13 [00:00<00:00, 277.02it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 192.17it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 234.77it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 193.48it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 208.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing document Ethiopian forces have recaptured key towns on the road to Tigray: The expanded size of the tensor (518) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [10, 518].  Tensor sizes: [1, 512]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 253.74it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 328.13it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 122.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing document Congo’s president has not kept his word: The expanded size of the tensor (672) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [8, 672].  Tensor sizes: [1, 512]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:00<00:00, 180.86it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 221.54it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 176.07it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 227.83it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 318.25it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 164.25it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 216.48it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 183.05it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 238.83it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 330.62it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 258.66it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 273.20it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 280.59it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 257.06it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 311.65it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 191.43it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 234.81it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 301.72it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 140.01it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 198.55it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 234.74it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 247.09it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 153.78it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 250.39it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 213.70it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 231.37it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 191.74it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 273.53it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 219.43it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 273.66it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 164.38it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 165.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing document Sudan’s democratic transition is upended by a second coup in two years: The expanded size of the tensor (532) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [8, 532].  Tensor sizes: [1, 512]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:00<00:00, 334.98it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 245.65it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 255.39it/s]\n",
      "100%|██████████| 34/34 [00:00<00:00, 260.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing document How kidnappers, zealots and rebels are making Nigeria ungovernable: The expanded size of the tensor (527) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [32, 527].  Tensor sizes: [1, 512]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 259.49it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 305.94it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 233.90it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 224.24it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 243.76it/s]\n",
      "100%|██████████| 16/16 [00:00<00:00, 236.99it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 208.31it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 200.79it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 185.55it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 289.34it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 237.82it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 239.34it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 196.14it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 217.58it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 175.82it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 264.55it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 225.73it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 286.34it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 247.49it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 234.67it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 232.45it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 248.39it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 245.52it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 238.24it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 285.61it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 297.53it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 170.63it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 212.14it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 345.81it/s]\n",
      "100%|██████████| 10/10 [00:00<00:00, 165.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing document Alpha Condé, the president of Guinea, is ousted in a coup: The expanded size of the tensor (540) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [10, 540].  Tensor sizes: [1, 512]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 328.94it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 263.47it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 256.04it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 290.52it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 209.36it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 179.52it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 209.34it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 268.89it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 248.82it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 300.70it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 245.04it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 321.70it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 257.13it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 238.56it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 345.20it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 198.95it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 229.93it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 181.34it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 225.19it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 136.18it/s]\n",
      "100%|██████████| 18/18 [00:00<00:00, 208.06it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 312.49it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 231.60it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 171.80it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 140.65it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 209.16it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 110.04it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 327.65it/s]\n",
      "100%|██████████| 35/35 [00:00<00:00, 187.75it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 229.60it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 244.79it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00, 317.91it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 292.93it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 190.74it/s]\n",
      "100%|██████████| 9/9 [00:00<00:00, 174.40it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 288.33it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 171.02it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 172.95it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 281.02it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 297.74it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 168.49it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 315.23it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 213.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing document Africa’s latest wave of covid-19 could be its worst yet: The expanded size of the tensor (519) must match the existing size (512) at non-singleton dimension 1.  Target sizes: [12, 519].  Tensor sizes: [1, 512]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 240.93it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 187.01it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 281.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 421.87it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 326.14it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 318.74it/s]\n",
      "100%|██████████| 12/12 [00:00<00:00, 189.94it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m docs:\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         doc, predict_entities = \u001b[43mquote_cue_source_extraction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m         ents.append(predict_entities)\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mquote_cue_source_extraction\u001b[39m\u001b[34m(doc)\u001b[39m\n\u001b[32m     11\u001b[39m paragraphs = doc[\u001b[33m'\u001b[39m\u001b[33mparagraphs\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# extract Cue, Source, and Quotes\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m predict_entities = \u001b[43mextract_quotes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparagraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_cofe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m doc, predict_entities\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 22\u001b[39m, in \u001b[36mextract_quotes\u001b[39m\u001b[34m(infer_str, model_cofe)\u001b[39m\n\u001b[32m     20\u001b[39m model_cofe.eval()\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     batch_preds = \u001b[43mmodel_cofe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     batch_pred_strs = tgidss2tgstrss(\n\u001b[32m     25\u001b[39m         batch_preds.data.cpu().numpy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch_preds, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m batch_preds, tag_file_path,\n\u001b[32m     26\u001b[39m         batch_data[\u001b[33m'\u001b[39m\u001b[33mlengths\u001b[39m\u001b[33m'\u001b[39m].cpu().numpy())\n\u001b[32m     28\u001b[39m     preds.extend(batch_pred_strs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Ahmed-home/1- Projects/oulu courses/Applied NLP/Oulu/Project/npat/src/cofenet/model/mod_bert.py:67\u001b[39m, in \u001b[36mModelBert_Cofe.predict\u001b[39m\u001b[34m(self, batch_data, output_weight, output_Z)\u001b[39m\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_data: \u001b[38;5;28mdict\u001b[39m, output_weight=\u001b[38;5;28;01mFalse\u001b[39;00m, output_Z=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m     words_hidden = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlayer_bert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtkidss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mattention_mask\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwdlens\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m     outputs = \u001b[38;5;28mself\u001b[39m.layer_enh.predict(words_hidden, batch_data[\u001b[33m'\u001b[39m\u001b[33mlengths\u001b[39m\u001b[33m'\u001b[39m], output_weight=output_weight, output_Z=output_Z)\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, \u001b[38;5;28mtuple\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Ahmed-home/1- Projects/oulu courses/Applied NLP/Oulu/Project/npat/src/cofenet/model/torch_utils/bert.py:31\u001b[39m, in \u001b[36mWordBert.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, wdlens, output_num)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     24\u001b[39m \u001b[33;03m:param input_ids: [batch, tk_seq + 1]\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[33;03m:param attention_mask: [batch, tk_seq + 1] or None\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[33;03m:param wdlens: [batch, wd_seq]\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[33;03m:return: [batch, wd_seq, hidden]\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# bert_output = [batch, tk_seq, hidden]\u001b[39;00m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# bert_output = self.bert(input_ids, attention_mask=attention_mask)[0]\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m bert_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bert_output) <= \u001b[32m2\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m output_num == \u001b[32m1\u001b[39m:\n\u001b[32m     34\u001b[39m     layer_hidden = bert_output[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1142\u001b[39m, in \u001b[36mBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m   1136\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m   1138\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m   1139\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m   1140\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m-> \u001b[39m\u001b[32m1142\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1154\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1155\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:695\u001b[39m, in \u001b[36mBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    684\u001b[39m     layer_outputs = \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(\n\u001b[32m    685\u001b[39m         layer_module.\u001b[34m__call__\u001b[39m,\n\u001b[32m    686\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    692\u001b[39m         output_attentions,\n\u001b[32m    693\u001b[39m     )\n\u001b[32m    694\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    699\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    703\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:627\u001b[39m, in \u001b[36mBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    624\u001b[39m     cross_attn_present_key_value = cross_attention_outputs[-\u001b[32m1\u001b[39m]\n\u001b[32m    625\u001b[39m     present_key_value = present_key_value + cross_attn_present_key_value\n\u001b[32m--> \u001b[39m\u001b[32m627\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    629\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    630\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    632\u001b[39m \u001b[38;5;66;03m# if decoder, return the attn key/values as the last output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/transformers/pytorch_utils.py:248\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    245\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    246\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:639\u001b[39m, in \u001b[36mBertLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    638\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m--> \u001b[39m\u001b[32m639\u001b[39m     intermediate_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    640\u001b[39m     layer_output = \u001b[38;5;28mself\u001b[39m.output(intermediate_output, attention_output)\n\u001b[32m    641\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:539\u001b[39m, in \u001b[36mBertIntermediate.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m539\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    540\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.intermediate_act_fn(hidden_states)\n\u001b[32m    541\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/nlp/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "ents = []\n",
    "for doc in docs:\n",
    "    try:\n",
    "        doc, predict_entities = quote_cue_source_extraction(doc)\n",
    "        ents.append(predict_entities)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing document {doc['title']}: {e}\")\n",
    "        ents.append([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04a4dfad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47515b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "563c72b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc['paragraphs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efa4e4af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc['paragraphs'][0].split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "62ea9ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I n the central marketplace of Gedaref, eastern Sudan, Mohammed Siddig counts the cost of the past year’s turmoil. The price of fuel, which he needs to run his farm near the border with Ethiopia, is up by about 300. School fees, which he pays for four of his children, have increased by 400. Yet just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut their subsidies. \"It’s totally unprofitable,\" Mr Siddig laments. His sesame and sorghum harvest recently fetched about half what it had the previous year. Now he is in debt, which he underscores by slapping onto the counter a bag of chickpeas that he is buying on credit.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc['paragraphs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7a2dafb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-source',\n",
       " 'I-source',\n",
       " 'B-cue',\n",
       " 'B-content',\n",
       " 'I-content',\n",
       " 'I-content',\n",
       " 'I-content',\n",
       " 'I-content',\n",
       " 'I-content',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'B-content',\n",
       " 'I-content',\n",
       " 'I-content',\n",
       " 'B-source',\n",
       " 'I-source',\n",
       " 'B-cue',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O',\n",
       " 'O']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_entities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c99234de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "116"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predict_entities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "942bc6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Token",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "labels",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "56df6810-4884-40eb-bd98-a89efd3affb6",
       "rows": [
        [
         "0",
         "I",
         "O"
        ],
        [
         "1",
         "n",
         "O"
        ],
        [
         "2",
         "the",
         "O"
        ],
        [
         "3",
         "central",
         "O"
        ],
        [
         "4",
         "marketplace",
         "O"
        ],
        [
         "5",
         "of",
         "O"
        ],
        [
         "6",
         "Gedaref,",
         "O"
        ],
        [
         "7",
         "eastern",
         "O"
        ],
        [
         "8",
         "Sudan,",
         "O"
        ],
        [
         "9",
         "Mohammed",
         "B-source"
        ],
        [
         "10",
         "Siddig",
         "I-source"
        ],
        [
         "11",
         "counts",
         "B-cue"
        ],
        [
         "12",
         "the",
         "B-content"
        ],
        [
         "13",
         "cost",
         "I-content"
        ],
        [
         "14",
         "of",
         "I-content"
        ],
        [
         "15",
         "the",
         "I-content"
        ],
        [
         "16",
         "past",
         "I-content"
        ],
        [
         "17",
         "year’s",
         "I-content"
        ],
        [
         "18",
         "turmoil.",
         "O"
        ],
        [
         "19",
         "The",
         "O"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 20
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Token</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>central</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marketplace</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>of</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gedaref,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>eastern</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sudan,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mohammed</td>\n",
       "      <td>B-source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Siddig</td>\n",
       "      <td>I-source</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>counts</td>\n",
       "      <td>B-cue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the</td>\n",
       "      <td>B-content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cost</td>\n",
       "      <td>I-content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>of</td>\n",
       "      <td>I-content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the</td>\n",
       "      <td>I-content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>past</td>\n",
       "      <td>I-content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>year’s</td>\n",
       "      <td>I-content</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>turmoil.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>The</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Token     labels\n",
       "0             I          O\n",
       "1             n          O\n",
       "2           the          O\n",
       "3       central          O\n",
       "4   marketplace          O\n",
       "5            of          O\n",
       "6      Gedaref,          O\n",
       "7       eastern          O\n",
       "8        Sudan,          O\n",
       "9      Mohammed   B-source\n",
       "10       Siddig   I-source\n",
       "11       counts      B-cue\n",
       "12          the  B-content\n",
       "13         cost  I-content\n",
       "14           of  I-content\n",
       "15          the  I-content\n",
       "16         past  I-content\n",
       "17       year’s  I-content\n",
       "18     turmoil.          O\n",
       "19          The          O"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "columns = ['Token', 'labels']\n",
    "data = []\n",
    "for token, label in zip(doc['paragraphs'][0].split(), predict_entities[0]):\n",
    "    data.append([token, label])\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df.head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a195c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e94339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "62c87f4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/27/2025 23:07:57 - INFO - \t missing_keys: []\n",
      "11/27/2025 23:07:57 - INFO - \t unexpected_keys: []\n",
      "11/27/2025 23:07:57 - INFO - \t mismatched_keys: []\n",
      "11/27/2025 23:07:57 - INFO - \t error_msgs: []\n",
      "11/27/2025 23:07:57 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n"
     ]
    }
   ],
   "source": [
    "from spacy.tokens import Doc, Span\n",
    "import spacy\n",
    "from typing import List\n",
    "from fastcoref import spacy_component\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "nlp.add_pipe(\"fastcoref\")\n",
    "\n",
    "def coref_resolver(txt, bio):\n",
    "    global nlp\n",
    "\n",
    "    def get_span_noun_indices(doc: Doc, cluster: List[List[int]]) -> List[int]:\n",
    "        spans = [doc[span[0]:span[1]+1] for span in cluster]\n",
    "        spans_pos = [[token.pos_ for token in span] for span in spans]\n",
    "        span_noun_indices = [i for i, span_pos in enumerate(spans_pos)\n",
    "            if any(pos in span_pos for pos in ['NOUN', 'PROPN'])]\n",
    "        return span_noun_indices\n",
    "\n",
    "    def get_cluster_head(doc: Doc, cluster: List[List[int]], noun_indices: List[int]):\n",
    "        head_idx = noun_indices[0]\n",
    "        head_start, head_end = cluster[head_idx]\n",
    "        head_span = doc[head_start:head_end+1]\n",
    "        return head_span, [head_start, head_end]\n",
    "\n",
    "    def is_containing_other_spans(span: List[int], all_spans: List[List[int]]):\n",
    "        return any([s[0] >= span[0] and s[1] <= span[1] and s != span for s in all_spans])\n",
    "\n",
    "    def improved_replace_corefs(document, clusters):\n",
    "        all_spans = [span for cluster in clusters for span in cluster]\n",
    "        coref_results = []\n",
    "        for cluster in clusters:\n",
    "            noun_indices = get_span_noun_indices(document, cluster)\n",
    "            if noun_indices:\n",
    "                mention_span, mention = get_cluster_head(document, cluster, noun_indices)\n",
    "                for coref in cluster:\n",
    "                    if coref != mention and not is_containing_other_spans(coref, all_spans):\n",
    "                        coref_results.append({\"coref_pos\": coref, \"refer\": mention_span.text})\n",
    "        return coref_results\n",
    "\n",
    "    try:\n",
    "        doc = nlp(txt)\n",
    "        coref_clusters = doc._.coref_clusters\n",
    "        clusters = []\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        for cluster in coref_clusters:\n",
    "            spans = []\n",
    "            \n",
    "            for mention in cluster:\n",
    "                start = mention[0]\n",
    "                end = mention[1] - 1  # match AllenNLP indexing\n",
    "                spans.append([start, end])\n",
    "            clusters.append(spans)\n",
    "    except Exception as e:\n",
    "        print(\"*\"*20)\n",
    "        print(f\"Error processing: {txt}\")\n",
    "        print(e)\n",
    "        print(\"*\"*20)\n",
    "        return []\n",
    "\n",
    "    # build spaCy doc with BIO entities\n",
    "    words = txt.split(' ')\n",
    "    spaces = [True] * len(words)\n",
    "    doc_ = Doc(nlp.vocab, words=words, spaces=spaces, ents=bio)\n",
    "    doc = nlp(doc_)\n",
    "    coref_results = improved_replace_corefs(doc, clusters)\n",
    "    return coref_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43405659",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/27/2025 23:08:06 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 112.80 examples/s]\n",
      "11/27/2025 23:08:11 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  2.85it/s]\n",
      "11/27/2025 23:08:12 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 137.14 examples/s]\n",
      "11/27/2025 23:08:17 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  5.47it/s]\n"
     ]
    }
   ],
   "source": [
    "coref_results = coref_resolver(doc['paragraphs'][0], predict_entities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d6d68044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'coref_pos': [140, 141],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [156, 158],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [235, 236],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [255, 257],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [439, 447],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [458, 460],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [552, 553],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [573, 574],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [641, 642],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38750af",
   "metadata": {},
   "outputs": [],
   "source": [
    "coref_results[0]['refer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22d2a8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b120083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_polarity(texts: list):\n",
    "#     global polarity_model\n",
    "#     return polarity_model(texts)\n",
    "\n",
    "\n",
    "\n",
    "def enhance_source(span, enhance_if_large_than=4):\n",
    "    global nlp\n",
    "    position = [span.start, span.end]\n",
    "    doc = nlp(Doc(nlp.vocab, words=span.text.split(' ')))\n",
    "    if len(doc) <= enhance_if_large_than: \n",
    "        return span.text, position\n",
    "\n",
    "    # get first person entity\n",
    "    ent = list(filter(lambda x: x.label_ == 'PERSON', doc.ents))[0]\n",
    "\n",
    "    left = []\n",
    "    for i in range(1,6):\n",
    "        tok = doc[ent.start-i]\n",
    "        if ent.start-i < 0 or tok.pos_ not in {\"PROPN\", \"PRON\"}: break\n",
    "        left.append(tok.text)\n",
    "\n",
    "    right = []\n",
    "    for i in range(1,6):\n",
    "        if ent.start+i > len(doc)-1 or tok.pos_ not in {\"PROPN\", \"PRON\"}: break\n",
    "        tok = doc[ent.start+i]\n",
    "        right.append(tok.text)\n",
    "\n",
    "\n",
    "    local_pos = [ent.start - len(left), ent.end + len(right)]\n",
    "    position[0] = position[0] + local_pos[0]\n",
    "    position[1] = position[1] - (len(doc) - local_pos[1])\n",
    "    return doc[local_pos[0]: local_pos[1]].text.strip(), position\n",
    "\n",
    "\n",
    "\n",
    "def entity_linking(paragraphs, bios):\n",
    "    global nlp\n",
    "\n",
    "    linked_entities = []\n",
    "    for i, content in enumerate(zip(paragraphs, bios)):\n",
    "        local_linked_entities = []\n",
    "        # decompress the tuple\n",
    "        paragraph, bio = content\n",
    "\n",
    "        # the previous pargraph preparation\n",
    "        add_words, add_bio = [], []\n",
    "        # in case of first paragraph will ignore it, becouse there is no pargraphs before first one.\n",
    "        if i != 0:\n",
    "            # split to words\n",
    "            add_words = paragraphs[i-1].split(' ')\n",
    "            add_bio = bios[i-1]\n",
    "\n",
    "        # split to words and combine the previous paragraph with the current one.\n",
    "        words = add_words + paragraph.split(' ')\n",
    "        # prepare the spaces \n",
    "        spaces = [True]*len(words)\n",
    "        # combine the previous bio with the current one.\n",
    "        bio_ = add_bio + bio \n",
    "\n",
    "        # create Doc with its entities\n",
    "        doc_ = Doc(nlp.vocab, words=words, spaces=spaces, ents=bio_)\n",
    "        # feed the doc to default spacy pipeline to get the dependency tree and POS tags\n",
    "        doc = nlp(doc_)\n",
    "\n",
    "        # assigne the new doc ents with our entites.\n",
    "        doc.ents = doc_.ents\n",
    "\n",
    "        cues = list(filter(lambda ent: ent.label_ == 'cue', doc.ents)) # get list of cue-verb entities\n",
    "        sources = list(filter(lambda ent: ent.label_ == 'source', doc.ents)) # get list of source entities\n",
    "        contents = list(filter(lambda ent: ent.label_ == 'content', doc.ents)) # get list of content entities\n",
    "\n",
    "        # loop on each cue\n",
    "        for cue in cues:\n",
    "            # get only the verb word from cue, becaues cue and has many words\n",
    "            verb = None\n",
    "            verbs = list(filter(lambda tok: tok.pos_ =='VERB', cue))\n",
    "            if len(verbs) > 0:\n",
    "                verb = verbs[0] # get the first one\n",
    "\n",
    "            # get the source of cue based on POS & dependency tree\n",
    "            try:\n",
    "                source = None\n",
    "                # check all verb's children, if any one of them is labeled as a source entity.\n",
    "                source_part = next((child for child in verb.children if child.ent_type_ == 'source'), None)\n",
    "                # in case if no verb's children exist as source entity, look at the head \"Conj\" \n",
    "                if source_part == None:\n",
    "                    temp_verb = verb\n",
    "                    # loop untill get the source\n",
    "                    out_ = 0\n",
    "                    while temp_verb.dep_ != 'ROOT' or temp_verb.pos_ != 'VERB':\n",
    "                        temp_verb = temp_verb.head\n",
    "                        source_part = next((child for child in temp_verb.children if child.ent_type_ == 'source'), None)\n",
    "                        if out_ > 5: break\n",
    "                        out_+=1\n",
    "                \n",
    "                # get the original entity of source_part \n",
    "                for ent in sources:\n",
    "                    if source_part.i >= ent.start and source_part.i <= ent.end:\n",
    "                        source = ent\n",
    "                        break\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                quote = None\n",
    "                # check all verb's children, if any one of them is labeled as a content entity.\n",
    "                qoute_part = next((child for child in verb.children if child.ent_type_ == 'content'), None)\n",
    "                if qoute_part == None and verb.head.ent_type_ == 'content':\n",
    "                    qoute_part = verb.head\n",
    "\n",
    "                # get the original entity of qoute_part \n",
    "                for ent in contents:\n",
    "                    if qoute_part.i >= ent.start and qoute_part.i <= ent.end:\n",
    "                        quote = ent\n",
    "                        break\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            try:\n",
    "                # to get only quotes from the current paragraph, and not include quotes from the previous one.\n",
    "                if quote[0].i >= len(add_words):\n",
    "                    enhanced_source, position = enhance_source(source)\n",
    "                    obj = {\"Speaker\": enhanced_source,\n",
    "                           \"Speaker_position\": position, # useing in corfrence resolution \n",
    "                           \"Cue\": verb.text,\n",
    "                           \"Quote\": quote.text,\n",
    "                        #    \"Quote_polarity\": get_polarity([quote.text])[0],\n",
    "                        #    \"Quote_summarization\": summerizer_model.predict(quote.text)[0] if len(quote.text.split(' ')) > 20 else quote.text\n",
    "                    }\n",
    "                    local_linked_entities.append(obj)\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        linked_entities.append(local_linked_entities)\n",
    "    return linked_entities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "87179a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11/27/2025 23:40:49 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 112.90 examples/s]\n",
      "11/27/2025 23:40:54 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  7.85it/s]\n",
      "11/27/2025 23:40:54 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 59.10 examples/s]\n",
      "11/27/2025 23:40:58 - INFO - \t ***** Running Inference on 1 texts *****\n",
      "Inference: 100%|██████████| 1/1 [00:00<00:00,  8.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[{'Speaker': 'Mohammed Siddig',\n",
       "   'Speaker_position': [9, 11],\n",
       "   'Cue': 'counts',\n",
       "   'Quote': 'the cost of the past year’s'}]]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraphs = [doc['paragraphs'][0]] \n",
    "linked_entities = entity_linking(paragraphs, [predict_entities[0]])\n",
    "linked_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "44e338ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Speaker', 'Speaker_position', 'Cue', 'Quote'])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linked_entities[0][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "008d8184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I n the central marketplace of Gedaref, eastern Sudan, Mohammed Siddig counts the cost of the past year’s turmoil. The price of fuel, which he needs to run his farm near the border with Ethiopia, is up by about 300. School fees, which he pays for four of his children, have increased by 400. Yet just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut their subsidies. \"It’s totally unprofitable,\" Mr Siddig laments. His sesame and sorghum harvest recently fetched about half what it had the previous year. Now he is in debt, which he underscores by slapping onto the counter a bag of chickpeas that he is buying on credit.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc['paragraphs'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "671f275d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Speaker': 'Mohammed Siddig',\n",
       " 'Speaker_position': [9, 11],\n",
       " 'Cue': 'counts',\n",
       " 'Quote': 'the cost of the past year’s'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linked_entities[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3d6a552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'coref_pos': [140, 141],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [156, 158],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [235, 236],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [255, 257],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [439, 447],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [458, 460],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [552, 553],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [573, 574],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'},\n",
       " {'coref_pos': [641, 642],\n",
       "  'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coref_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405cdcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_coref_on_linked_entities(linking_out, coref_out):\n",
    "    linking_qouts = []  \n",
    "    for paragraph_links, coref_links in zip(linking_out, coref_out):\n",
    "        local_linkes = []\n",
    "        # import ipdb; ipdb.set_trace()\n",
    "        for quote in paragraph_links:\n",
    "            print(coref_links)\n",
    "            print(quote)\n",
    "            source_start, source_end = quote['Speaker_position'][0], quote['Speaker_position'][1]-1  \n",
    "\n",
    "            new_source = list(filter(lambda x: x['coref_pos'][0] <= source_start and x['coref_pos'][1] >= source_end , coref_links))\n",
    "            new_link = {k:v for k, v in quote.items() if k != 'Speaker_position'}\n",
    "            if len(new_source) > 0:\n",
    "                new_link['Speaker'] = new_source[0]['refer']\n",
    "            \n",
    "            local_linkes.append(new_link)\n",
    "         \n",
    "        linking_qouts.append(local_linkes)\n",
    "    return linking_qouts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3430451a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'coref_pos': [140, 141], 'refer': 'just as unrest at nearby Port Sudan hurt farmers’ exports, the state-owned agricultural bank cut'}]\n",
      "{'Speaker': 'Mohammed Siddig', 'Speaker_position': [9, 11], 'Cue': 'counts', 'Quote': 'the cost of the past year’s'}\n"
     ]
    }
   ],
   "source": [
    "linked_entities = apply_coref_on_linked_entities([linked_entities[0]], [[coref_results[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7b51da5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'Speaker': 'Mohammed Siddig',\n",
       "   'Cue': 'counts',\n",
       "   'Quote': 'the cost of the past year’s'}]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linked_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3a99f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c00bd1a",
   "metadata": {},
   "source": [
    "## Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9f7a72bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[0;93m2025-11-29 12:51:04.152505002 [W:onnxruntime:Default, device_discovery.cc:164 DiscoverDevicesForPlatform] GPU device discovery failed: device_discovery.cc:89 ReadFileContents Failed to open file: \"/sys/class/drm/card3/device/vendor\"\u001b[m\n",
      "/home/ahmed/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:26<00:00, 3.18MiB/s]\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "# setup Chroma in-memory, for easy prototyping. Can add persistence easily!\n",
    "client = chromadb.Client()\n",
    "\n",
    "# Create collection. get_collection, get_or_create_collection, delete_collection also available!\n",
    "collection = client.create_collection(\"test-documents\")\n",
    "\n",
    "# Add docs to the collection. Can also update and delete. Row-based API coming soon!\n",
    "collection.add(\n",
    "    documents=[\"This is document1\", \"This is document2\"], # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
    "    metadatas=[{\"source\": \"notion\"}, {\"source\": \"google-docs\"}], # filter on these!\n",
    "    ids=[\"doc1\", \"doc2\"], # unique for each doc\n",
    ")\n",
    "\n",
    "# Query/search 2 most similar results. You can also .get by id\n",
    "results = collection.query(\n",
    "    query_texts=[\"This is a query document\"],\n",
    "    n_results=2,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "    # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0128d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ids': [['doc1', 'doc2']],\n",
       " 'embeddings': None,\n",
       " 'documents': [['This is document1', 'This is document2']],\n",
       " 'uris': None,\n",
       " 'included': ['metadatas', 'documents', 'distances'],\n",
       " 'data': None,\n",
       " 'metadatas': [[{'source': 'notion'}, {'source': 'google-docs'}]],\n",
       " 'distances': [[0.9026353359222412, 1.035815954208374]]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c057d3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdd9926",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
